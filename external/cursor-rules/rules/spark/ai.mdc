# AI Integration Patterns

## Chat Models

### Basic Chat

```typescript
const prompt = new ChatPrompt({
  model: new OpenAIModel({
    model: 'gpt-4',
    apiKey: process.env.OPENAI_API_KEY,
  }),
  instructions: 'You are a helpful assistant.',
});

const response = await prompt.send('Hello!');
await send(response.content);
```

### Streaming Responses

```typescript
const prompt = new ChatPrompt({
  model: new OpenAIModel(),
  instructions: template,
});

await prompt.send(input, {
  onChunk: (chunk) => {
    stream.emit(new MessageActivity(chunk));
  },
});
```

## Function Calling

### Basic Functions

```typescript
const prompt = new ChatPrompt({
  model: new OpenAIModel(),
  instructions: template,
}).function(
  'get_weather',
  'Get weather data',
  {
    parameters: {
      location: { type: 'string' },
      unit: { type: 'string', enum: ['celsius', 'fahrenheit'] },
    },
  },
  async ({ location, unit }) => {
    return await weatherApi.get(location, unit);
  }
);
```

### Function Chaining

```typescript
const prompt = new ChatPrompt({
  model: new OpenAIModel(),
})
  .function('search_products', 'Search product database', async (query) => {
    return await db.products.search(query);
  })
  .function('get_inventory', 'Get inventory levels', async (productId) => {
    return await db.inventory.get(productId);
  })
  .function('place_order', 'Place an order', async (orderDetails) => {
    return await orders.create(orderDetails);
  });
```

## Memory Management

### Short-Term Memory

```typescript
const memory = new LocalMemory({
  maxMessages: 10,
});

const prompt = new ChatPrompt({
  model: new OpenAIModel(),
  memory,
  instructions: template,
});

// Memory auto-managed during conversations
await prompt.send(input);
```

### Long-Term Memory

```typescript
const storage = new LocalStorage();
const memory = new LongTermMemory({
  storage,
  namespace: `chat:${userId}`,
  maxTokens: 4000,
});

// Persist important context
await memory.add({
  role: 'system',
  content: 'User preferences updated',
});

// Clear old data
await memory.clear({
  before: new Date().getTime() - 24 * 60 * 60 * 1000,
});
```

## Multi-Modal Support

### Image Analysis

```typescript
app.on('image', async ({ activity }) => {
  const prompt = new ChatPrompt({
    model: new OpenAIModel(),
    instructions: 'Analyze the image and describe what you see.',
  });

  const description = await prompt.analyzeImage(activity.attachments[0]);
  await send(`I see: ${description}`);
});
```

### Audio Processing

```typescript
app.on('audio', async ({ activity }) => {
  const prompt = new ChatPrompt({
    model: new OpenAIModel(),
    instructions: 'Transcribe and summarize the audio.',
  });

  const { transcript, summary } = await prompt.processAudio(activity.attachments[0]);
  await send(createAudioCard(transcript, summary));
});
```

## Assistant Chaining

### Expert Chain

```typescript
const researcher = new ChatPrompt({
  model: new OpenAIModel(),
  instructions: researcherTemplate,
});

const writer = new ChatPrompt({
  model: new OpenAIModel(),
  instructions: writerTemplate,
});

const reviewer = new ChatPrompt({
  model: new OpenAIModel(),
  instructions: reviewerTemplate,
});

// Chain assistants
const research = await researcher.send(topic);
const draft = await writer.send(research.content);
const final = await reviewer.send(draft.content);
```

### Multi-Modal Chain

```typescript
const imageAnalyzer = new ChatPrompt({
  model: new OpenAIModel(),
  instructions: 'Analyze images in detail.',
});

const reporter = new ChatPrompt({
  model: new OpenAIModel(),
  instructions: 'Create reports from analysis.',
});

// Process image through chain
const analysis = await imageAnalyzer.analyzeImage(image);
const report = await reporter.send(analysis);
await send(createReportCard(report));
```

## Templates

### String Template

```typescript
const template = new StringTemplate(`
You are an AI assistant with these traits:
- ${personality}
- ${style}
- ${tone}
`);

const prompt = new ChatPrompt({
  model: new OpenAIModel(),
  instructions: template,
});
```

### Dynamic Template

```typescript
const template = new DynamicTemplate(async (context) => {
  const user = await getUser(context.userId);
  const prefs = await getPreferences(user.id);

  return `
    User: ${user.name}
    Language: ${prefs.language}
    Style: ${prefs.communicationStyle}
  `;
});
```

## Error Handling

### Graceful Fallbacks

```typescript
try {
  const response = await prompt.send(input);
  await send(response.content);
} catch (error) {
  if (error instanceof TokenLimitError) {
    await send('I need to clear some memory...');
    await memory.clear();
    return await prompt.send(input);
  }

  if (error instanceof ModelError) {
    await send('Let me try a different approach...');
    return await fallbackPrompt.send(input);
  }

  throw error;
}
```

### Rate Limiting

```typescript
const limiter = new RateLimiter({
  maxTokens: 100000,
  window: '1m',
});

const prompt = new ChatPrompt({
  model: new OpenAIModel(),
  rateLimiter: limiter,
});

// Auto-handles rate limits
await prompt.send(input);
```
